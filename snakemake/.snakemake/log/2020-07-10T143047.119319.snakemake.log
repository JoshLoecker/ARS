Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 12
Rules claiming more threads will be scaled down.
Conda environments: ignored
Job counts:
	count	jobs
	1	all
	1	barcode
	2

[Fri Jul 10 14:30:47 2020]
rule barcode:
    input: /Users/joshl/PycharmProjects/ARS/Results/Basecall/FAL03879_67a0761e_11/fastq_runid_67a0761ea992f55d7000e748e88761780ca1bb60_0_0.fastq
    output: /Users/joshl/PycharmProjects/ARS/Results/Barcode/FAL03879_67a0761e_11/fastq_runid_67a0761ea992f55d7000e748e88761780ca1bb60_0_0.fastq
    jobid: 9
    wildcards: fastq_files=FAL03879_67a0761e_11/fastq_runid_67a0761ea992f55d7000e748e88761780ca1bb60_0_0

[Fri Jul 10 14:30:47 2020]
Error in rule barcode:
    jobid: 9
    output: /Users/joshl/PycharmProjects/ARS/Results/Barcode/FAL03879_67a0761e_11/fastq_runid_67a0761ea992f55d7000e748e88761780ca1bb60_0_0.fastq
    shell:
        INPUT_DIREC=`python3 /Users/joshl/PycharmProjects/ARS/Results/snakemake/scripts/ReturnInputDirectories.py`echo $INPUT_DIREC
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /Users/joshl/PycharmProjects/ARS/snakemake/.snakemake/log/2020-07-10T143047.119319.snakemake.log
