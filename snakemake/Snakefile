import os
configfile: "config.yaml"

def return_barcode_numbers(path: str):
    """
    This function will return a list of barcode numbers under the directory passed in
    Args:
        path: The directory that should be searched
    Returns: A list of strings containing directory names
    """
    barcode_numbers = set()
    for item in os.scandir(path):
        item = item.name
        if "barcode" in item:
            barcode_numbers.add(item)
        elif "unclassified" in item:
            barcode_numbers.add(item)
    return barcode_numbers

def basecall_barcode_merge_files(wildcards):
    checkpoint_output = checkpoints.basecall_barcode.get(**wildcards).output[0]
    barcodes = set()  # a set is like a list, but only stores unique values
    for folder in os.listdir(checkpoint_output):
        full_path = os.path.join(checkpoint_output, folder)
        if Path(full_path).is_dir():
            barcodes.add(folder)

    merge_files = [config['results_folder'] + "Barcode/" + barcode + ".merged.fastq" for barcode in barcodes]
    return merge_files

def nanoqc_pre_trim(wildcards):
    checkpoint_output = checkpoints.basecall_barcode.get(**wildcards).output[0]
    return expand(
        config['results_folder'] + "NanoQC/Pre-Trim/{barcode}",
        barcode=return_barcode_numbers(checkpoint_output)
    )

def trim_reads(wildcards):
    checkpoint_output = checkpoints.basecall_barcode.get(**wildcards).output[0]
    return expand(
        config['results_folder'] + "Trim/{barcode}.trim.fastq",
        barcode=return_barcode_numbers(checkpoint_output)
    )

def nanoqc_post_trim(wildcards):
    checkpoint_output = checkpoints.basecall_barcode.get(**wildcards).output[0]
    return expand(
        config['results_folder'] + "NanoQC/Post-Trim/{barcode}",
        barcode=return_barcode_numbers(checkpoint_output)
    )

def NanoFilt(wildcards):
    checkpoint_output = checkpoints.basecall_barcode.get(**wildcards).output[0]
    return expand(
        config['results_folder'] + "NanoFilt/{barcode}.nanofilt.fastq",
        barcode=return_barcode_numbers(checkpoint_output)
    )

def guppy_aligner(wildcards):
    checkpoint_output = checkpoints.basecall_barcode.get(**wildcards).output[0]
    return expand(
        config['results_folder'] + "Alignment/guppy/sam_files/{barcode}.guppy.sam",
               barcode=return_barcode_numbers(checkpoint_output)
    )

def minimap_aligner(wildcards):
    checkpoint_output = checkpoints.basecall_barcode.get(**wildcards).output[0]
    return expand(
        config['results_folder'] + "Alignment/minimap/{barcode}.minimap.sam",
        barcode=return_barcode_numbers(checkpoint_output)
    )

def vsearch_aligner(wildcards):
    checkpoint_output = checkpoints.basecall_barcode.get(**wildcards).output[0]
    return expand(
        config['results_folder'] + "Alignment/vsearch/{barcode}.vsearch.uc",
        barcode=return_barcode_numbers(checkpoint_output)
    )

def nanoplot(wildcards):
    checkpoint_output = checkpoints.basecall_barcode.get(**wildcards).output[0]
    return expand(
        config['results_folder'] + "Visuals/NanoPlot/{barcode}/",
        barcode=return_barcode_numbers(checkpoint_output)
    )

def plotly_multi_color(wildcards):
    checkpoint_output = checkpoints.basecall_barcode.get(**wildcards).output[0]
    return expand(
        config['results_folder'] + "Visuals/Plotly/{barcode}/multi.color.histogram.html",
        barcode=return_barcode_numbers(checkpoint_output)
    )



FAST5_FILES = glob_wildcards(config['results_folder'] + "DataFiles/fast5/{fast5_file}.fast5").fast5_file
rule all:
    input:
        basecall_barcode_merge_files,
        config['results_folder'] + "CountReads/count.reads.post.merge.csv",
        nanoqc_pre_trim,
        trim_reads,
        nanoqc_post_trim,
        NanoFilt,
        guppy_aligner,
        minimap_aligner,
        vsearch_aligner,
        nanoplot,
        config['results_folder'] + "Visuals/Plotly/single.color.histogram.html",
        # plotly_multi_color



checkpoint basecall_barcode:
    input:
        config['results_folder'] + "DataFiles/fast5/"
    output:
        directory(config['results_folder'] + ".barcodeTempOutput/")
    params:
        configuration = config['basecall_configuration'],
        barcode_kits = config['barcode_kit'],
        callers = config['num_callers'],
        threads_per_caller = config['num_threads_per_caller']
    conda:
        "envs/pythonEnv.yaml"
    shell:
        "guppy_basecaller "
        "--config {params.configuration} "
        "--input_path {input} "
        "--save_path {output} "
        "--barcode_kits {params.barcode_kits} "
        "--num_callers {params.callers} "
        "--cpu_threads_per_caller {params.threads_per_caller} "
        "--recursive "

        " && "
        "echo BASECALL: {output}"



def merge_files_input(wildcards):
    import glob
    return glob.glob(config['results_folder'] + f".barcodeTempOutput/{wildcards.barcode}/*.fastq")
rule merge_files:
    input:
        merge_files_input
    output:
        config['results_folder'] + "Barcode/{barcode}.merged.fastq"
    params:
        input_folder = config['results_folder'] + ".barcodeTempOutput",
        save_folder = config['results_folder'] + "Barcode"
    shell:
        r"""
        echo {input}
        for item in {input}; do
            cat $item >> {output}
            #rm $item
        done
        
        # move other files out of .barcodeTempOutput and into the save directory
        # we are only going to move them if they are present
        if [[ -f {params.input_folder}/*.txt ]]; then
            mv {params.input_folder}/*.txt {params.save_folder}/
        fi
        
        if [[ -f {params.input_folder}/*.log ]]; then
            mv {params.input_folder}/*.log {params.save_folder}/
        fi
        
        if [[ -f {params.input_folder}/*.js ]]; then
            mv {params.input_folder}/*.js {params.save_folder}/
        fi
        """



rule count_post_merge_reads:
    input:
        expand(config['results_folder'] + "Barcode/{barcode}.merged.fastq",
               barcode=return_barcode_numbers(config['results_folder'] + ".barcodeTempOutput/"))
    output:
        config['results_folder'] + "CountReads/count.reads.post.merge.csv"
    run:
        # import libraries
        import csv
        from collections import OrderedDict

        # iterate through and open each file in the input stream
        total_reads_dict = {}
        for file_path in input:

            # get the total number of lines in the file
            total_lines = len(open(file_path, 'r').readlines())

            # we know that fastq files have four lines per read, and fasta files have two lines per read. We will divide the file by the appropriate number
            if ".fastq" in file_path:
                number_of_reads = int(total_lines / 4)
            else:
                number_of_reads = int(total_lines / 2)

            # collect the barcode number from the file path
            file_name = os.path.basename(file_path)  # get the file name
            barcode_number = file_name.split(".")[0]  # get the barcode number

            # now add the barcode number with the total number of reads to our dictionary
            total_reads_dict[barcode_number] = number_of_reads

        # sort the reads so it is easy to find them in the resulting file
        # https://docs.python.org/2/library/collections.html#collections.OrderedDict
        total_reads_dict = OrderedDict( sorted(total_reads_dict.items(), key=lambda x: x[0]) )

        # now write the reads to our csv file
        with open(output[0], 'w') as output_stream:
            csv_writer = csv.writer(output_stream, delimiter="\t")

            # write a simple header row
            csv_writer.writerow(["barcode", "reads"])

            # write our barcode number and reads in barcode in the format of: barcode## READS
            for barcode in total_reads_dict.keys():
                row = [barcode, total_reads_dict[barcode]]
                csv_writer.writerow(row)



rule NanoQCPreTrim:
    input:
        rules.merge_files.output[0]
    output:
        directory(config['results_folder'] + "NanoQC/Pre-Trim/{barcode}")
    shell:
        r"""
        nanoQC -o {output} {input}
        """


rule trim:
    input:
        rules.merge_files.output[0]
    output:
        config['results_folder'] + "Trim/{barcode}.trim.fastq"
    params:
        three_prime_adapter = config['trim_three_prime_adapter'],
        five_prime_adapter = config['trim_five_prime_adapter'],
        error_rate = config['trim_error_rate']
    shell:
        r"""
        cutadapt \
        --revcomp \
        --quiet \
        --cores 0 \
        --adapter {params.three_prime_adapter} \
        --front {params.five_prime_adapter} \
        --error-rate {params.error_rate} \
        --output {output} \
        {input}
        """



rule NanoQCPostTrim:
    input:
        rules.trim.output[0]
    output:
        directory(config['results_folder'] + "NanoQC/Post-Trim/{barcode}")
    shell:
        r"""
        nanoQC -o {output} {input}
        """



rule NanoFilt:
    input:
        rules.trim.output[0]
    output:
        config['results_folder'] + "NanoFilt/{barcode}.nanofilt.fastq"
    shell:
        r"""
        touch {output}
        NanoFilt {input} > {output}
        """



rule guppy_aligner:
    input:
        rules.NanoFilt.output[0]
    output:
        sam_files = config['results_folder'] + "Alignment/guppy/sam_files/{barcode}.guppy.sam",
        alignment_summary = config['results_folder'] + "Alignment/guppy/alignment_summary/{barcode}.alignment.summary.csv",
        log_file = config['results_folder'] + "Alignment/guppy/logs/{barcode}.guppy.log",
    params:
        temp_input = config['results_folder'] + "Alignment/guppy/.{barcode}.temp.input",
        temp_output = config['results_folder'] + "Alignment/guppy/.{barcode}.temp.output",
        alignment_reference = config['alignment_reference_file']
    shell:
        r"""
        # move input files to our temp folder
        # this is required because guppy_aligner wants folders as input
        mkdir -p {params.temp_input}
        cp {input} {params.temp_input}
        
        # run alignment
        guppy_aligner \
        --input_path {params.temp_input} \
        --save_path {params.temp_output} \
        --align_ref {params.alignment_reference}
        
        # move files from the temp output to the appropriate folders
        # a temp output allows for better organization
        mv {params.temp_output}/*.sam {output.sam_files}
        mv {params.temp_output}/*.txt {output.alignment_summary}
        mv {params.temp_output}/*.log {output.log_file}
        
        # remove our temporary input and output files
        rm -rf {params.temp_input} {params.temp_output}
        """



rule minimap_aligner:
    input:
        rules.NanoFilt.output[0]
    output:
        config['results_folder'] + "Alignment/minimap/{barcode}.minimap.sam"
    params:
        alignment_reference = config['alignment_reference_file']
    shell:
        r"""
        touch {output}
        
        minimap2 \
        -ax map-ont \
        {params.alignment_reference} \
        {input} > {output}
        """



rule fq2fa:
    input:
        rules.NanoFilt.output[0]
    output:
        temp(config['results_folder'] + "Alignment/vsearch/.{barcode}.temp.fasta")
    shell:
        r"""
        seqkit fq2fa {input} > {output}
        """
rule vsearch_aligner:
    input:
        rules.fq2fa.output[0]
    output:
        config['results_folder'] + "Alignment/vsearch/{barcode}.vsearch.uc"
    params:
        alignment_reference = config['alignment_reference_file']
    shell:
        r"""
        vsearch \
        --usearch_global \
        {input} \
        --db {params.alignment_reference} \
        --id 0 \
        --uc {output} \
        --quiet
        """



rule nanoplot:
    input:
        rules.NanoFilt.output[0]
    output:
        directory(config['results_folder'] + "Visuals/NanoPlot/{barcode}/")
    params:
        barcode = "{barcode}"
    shell:
        r"""
        NanoPlot --fastq {input} --outdir {output}
        """



rule plotly_single_color:
    input:
        rules.count_post_merge_reads.output[0]
    output:
        config['results_folder'] + "Visuals/Plotly/single.color.histogram.html"
    script:
        "scripts/PlotlySingleColorHistogram.py"
rule plotly_multi_color:
    input:
         rules.NanoFilt.output[0]
    output:
        config['results_folder'] + "Visuals/Plotly/{barcode}/multi.color.histogram.html"
    script:
        "scripts/PlotlyMultiColorHistogram.py"
