import os
configfile: "config.yaml"

def ReturnBarcodeTextFileNames():
    folder_numbers = list()
    directory_path = config['results_folder'] + "Basecall"
    directories = os.listdir(directory_path)
    for item in directories:

    # we want to exclude any 'hidden' directories, as the directories we are interested in do not start with '.'
        if item[0] is not ".":
            folder_number = item.split("_")[-1]
            folder_numbers.append(folder_number)
    return folder_numbers

ReturnBarcodeTextFileNames()

# Wildcard section; this is how file names will be retrieved
# commas are added after the file name to "unpack" the tuple that is generated
BASECALL_SAMPLES, = glob_wildcards(config['results_folder'] + "DataFiles/fast5/{fast5_file}.fast5")
BARCODE_FILE_NUMBER = ReturnBarcodeTextFileNames()
TRIM_SAMPLES, = glob_wildcards(config['results_folder'] + "Barcode/{fastq_file}.fastq")

rule all:
    input:
        # basecall
        expand(config['results_folder'] + "Basecall/{fast5_file}", fast5_file=BASECALL_SAMPLES),

        # barcode
        expand(config['results_folder'] + "Barcode/basecall_id_{run_id}_delete_to_run_again", run_id=BARCODE_FILE_NUMBER),

        # merge files
        config['results_folder'] + "Barcode/merge_files_delete_this_to_merge_again",

        # trim reads
        # expand(config['results_folder'] + "Trim/{fastq_file}.trimmed.fastq", fastq_file=TRIM_SAMPLES)

rule basecall:
    input:
        config['results_folder'] + "DataFiles/fast5/{fast5_file}.fast5"
    output:
        directory(config['results_folder'] + "Basecall/{fast5_file}")
    conda:
        "envs/pythonEnv.yaml"
    shell:
        "ls {input}"

        " | "  # pipe results from `ls {input}` into guppy_basecaller

        # we are not giving guppy an input path. It will assume the input from the `ls` command
        "guppy_basecaller "
        "--quiet "
        "--save_path {output} "
        "--config dna_r9.4.1_450bps_fast.cfg "
        "--num_callers 1 "
        "--cpu_threads_per_caller 2 "

        " && "

        "echo BASECALL FILE OUTPUT: {output}"


"""
Merging files after barcoding comes with a challenge
Snakemake will see the missing `output` files, and think that barcoding needs to be ran again
To overcome this, we will `touch` an output file when this process is done
This allows us to move the real output files around (with `rule merge_files`), without having
    to redo barcoding every time because snakemake thinks it has not been ran yet

To get around the issue of showing the number of barcodes that need to be ran, we will create a 'hidden' file
    by placing a period in front of a text file, but keep our actual output directories as a parameter
This allows us to still manipulate the output in `rule merge_files`, while still letting snakemake know that
    the barcodes do not need to be run

"""
rule barcode:
    input:
        config['results_folder'] + "Basecall/"
    output:
        touch(config['results_folder'] + "Barcode/basecall_id_{run_id}_delete_to_run_again")
    params:
        real_output = config['results_folder'] + "Barcode/"
    conda:
        "envs/pythonEnv.yaml"
    shell:
        "guppy_barcoder "
        "--recursive "
        "--quiet "
        "--input_path {input} "
        "--save_path {params.real_output} "
        "--config configuration.cfg "
        "--worker_threads 2 "
        "--barcode_kits EXP-PBC096 "
        "--require_barcodes_both_ends "

        " && "

        "echo BARCODE FILE OUTPUT: {params.real_output}"

"""
As in the `rule barcode`, a similar practice is happening here
It is not possible to use the same input and output within a rule in snakemake, otherwise a cyclic dependency occurs
To get around this, we are going to simply create a file when this rule is complete, indicating that merging has
    occurred
This rule will not show the total number of files that need to be concatenated, as this process is very fast
We are also using the output from `rule barcode` as input here so this rule does not complete before barcoding is done
"""
rule merge_files:
    input:
        barcode_folders = config['results_folder'] + "Barcode",
        barcode_output_status = expand(config['results_folder'] + "Barcode/basecall_id_{run_id}_delete_to_run_again", run_id=BARCODE_FILE_NUMBER)
    output:
        touch(config['results_folder'] + "Barcode/merge_files_delete_this_to_merge_again")
    run:
        print("Starting to merge")
        # import libraries needed to find files, search for names, and move files
        import os
        import shutil
        import re

        # get our parent folder so we don't have to type `rules.merge_files.input` every time
        parent_folder = str(rules.merge_files.input.barcode_folders)

        # iterate through each directory in our parent folder
        for root, directories, files in os.walk(parent_folder):
            for directory in directories:

                # get the number of files in the directory
                current_dir_path = os.path.join(root, directory)
                number_of_files = len(os.listdir(current_dir_path))

                # get the old file path
                old_file_path = current_dir_path + "/" + str(os.listdir(current_dir_path)[0])

                # find its barcode number (to set a new name)
                barcode_number = re.search("(barcode)[0-9]{2}", old_file_path)
                if barcode_number is None:
                    barcode_number = re.search("(unclassified)", old_file_path)
                barcode_number = old_file_path[barcode_number.start():barcode_number.end()]

                # create our new file path
                new_file_path = current_dir_path + "/{0}.merged.fastq".format(barcode_number)

                # we only need to rename the file (technically move it) from the old path to the new path
                # both paths are in the same folder, just different names
                if number_of_files < 2:

                    # move the file to its new location
                    shutil.copy2(old_file_path, new_file_path)
                    os.remove(old_file_path)

                # we need to concatenate if there are 2 or more files in the directory
                else:
                    # first get the files we need to concatenate
                    files_to_concatenate = os.listdir(current_dir_path)

                    try:
                        open(new_file_path, 'r').close()
                    # we did not find the file, create one instead
                    except FileNotFoundError:
                        open(new_file_path, 'w').close()

                    # now open the new file as output_stream to write data
                    with open(new_file_path, 'a') as output_stream:

                        # iterate through each of our files to concatenate
                        for file in files_to_concatenate:

                            # create our input file path
                            input_file_path = current_dir_path + "/" + file

                            # now open our input file path as input_stream so we can read data
                            with open(input_file_path, 'r') as input_stream:

                                # iterate through each line in the file and write it to our new file
                                for each_line in input_stream:
                                    output_stream.write(each_line)

                    # we can now delete the old files
                    for file in files_to_concatenate:
                        delete_file_path = current_dir_path + "/" + file
                        os.remove(delete_file_path)

# TODO: Cutadapt throws error talking about file extensions
rule trim_reads:
    input:
        config['results_folder'] + "Barcode/{fastq_file}.fastq"
    output:
        config['results_folder'] + "Trim/{fastq_file}.trimmed.fastq"
    params:
        three_prime_adapter = "ACTTGCCTGTCGCTCTATCTTCTACCTTGTTACGACTT",
        five_prime_adapter = "TTTCTGTTGGTGCTGATATTGCAGRGTTYGATYMTGGCTCAG",
        error_rate = 0.15
    shell:
        "cutadapt "
        "--revcomp "
        # "--quiet "
        "--cores 0 "  # auto assign cores
        "--adapter {params.three_prime_adapter} "
        "--front {params.five_prime_adapter} "
        "--error-rate {params.error_rate} "
        "--output {output} "
        "{input}"